{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5_Problem3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmKqk__wjd_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import collections\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "import math\n",
        "import pickle,gzip\n",
        "import scipy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVgGHK50sIjS",
        "colab_type": "code",
        "outputId": "5d571142-7e7d-4e75-82ae-cad5d36b1d19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi1jbVecj0Vz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open(\"/content/drive/My Drive/CS25025/HW5/wiki-text.txt\",\"r\")\n",
        "corpus = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ-vYABZqhUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make a list of words from Wikipedia corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28vsZlgHj0Xr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wiki = re.findall(r'\\w+', corpus.lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF2dnBC9Saqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utPsHgS0qsg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove words that appear less than 500 times "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp4XaS9nrokS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "counter = collections.Counter(wiki)\n",
        "counter = collections.Counter(dict(filter(lambda x: x[1] >= 8, counter.items())))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv24LkMPs_e7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove all the words that appear in the stopwords list of nltk package"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd42zi2XaPNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znw0HATvj0cQ",
        "colab_type": "code",
        "outputId": "662d8cca-624b-4617-b20a-cb1037ffcd34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "counter = collections.Counter(dict(filter(lambda x: x[0] not in stop_words, counter.items())))\n",
        "list(counter.items())[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('anarchism', 157),\n",
              " ('originated', 73),\n",
              " ('term', 777),\n",
              " ('abuse', 46),\n",
              " ('first', 3444)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naA1RcDsa032",
        "colab_type": "code",
        "outputId": "a7028e14-b59b-4268-8f42-5242e41c6838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "counter[\"physics\"]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "173"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0GKFCqgthub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Applying the filter of \"at least 10 appearances\", we get the vocabulary whose \n",
        "# length is close to 15000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfulXYRLj0ep",
        "colab_type": "code",
        "outputId": "d761e8f2-b457-4eee-dc11-585631b59d16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(list(counter.keys())))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKuZpCyca52h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "V = [i for i in list(counter.keys())]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0CP7Ka5anSi",
        "colab_type": "code",
        "outputId": "aa4248e5-cfa4-4ea5-c9a9-cf346becb840",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"physics\" in V)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux6VTvyYxqG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Part (a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpJyAbOXx_55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use symmetric window size of 5 to find all word-context pairs "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK3uAqjjj0gz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "win = 5\n",
        "sp = collections.Counter()\n",
        "for i in range(len(wiki)):\n",
        "    section = wiki[max(0,i-win):i]+wiki[i+1:min(len(wiki),i+1+win)]\n",
        "    for context in section:\n",
        "        sp[(wiki[i], context)] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDz119yB359H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find the number of word-context pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5BZHqHVj0jQ",
        "colab_type": "code",
        "outputId": "f0abec28-2bd4-4b67-eb72-8ae5b946da35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c = sum(list(sp.values()))\n",
        "print(c)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19671140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcWD3rzU41G7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a function that calculates N^p(w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpdvHDPllzlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_np(sp, w):\n",
        "    return sum([sp[x] for x in sp if w in x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0qDLTAbJhSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In this part, we need to find M_ij as given in the instructions. However, even \n",
        "# with GPU, the computation time is beyond reasonable. Therefore, I decided to \n",
        "# find alternative ways to calculate N^p(w). \n",
        "# The intuition is that the more often a word appears in the corpus, the more \n",
        "# often it will appear in S_p. I believe that the correlation could be somewhat \n",
        "# linear, and hence we can normalize this value. This way, we can find N^p(w) \n",
        "# value much easier. For example, "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht1xEuJllzp2",
        "colab_type": "code",
        "outputId": "920acde7-c292-4c44-f272-360992fb581a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(compute_np(sp, \"abuse\") / counter[\"abuse\"])\n",
        "print(compute_np(sp, \"first\") / counter[\"first\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20.0\n",
            "19.98199767711963\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulogxaoRKfhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Indeed, the intuition was right and the N^p(w) value is 20 times the counter[w]\n",
        "# value. From now one, let's use 20*counter[w] to find N^p(w), instead of \n",
        "# repeating the compute_np(sp, w) function so many times. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFlwf5QQlzsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_M(w_i, w_j, sp):\n",
        "    return (math.log(((sp[(w_i,w_j)]+1)*c)/((counter[w_i]*20)*(counter[w_j]*20))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU3hd83VLG6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a function that finds the PMI matrix "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx4NoQRNlzud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_PMI(sp, V):\n",
        "    M = np.zeros((len(V),len(V)))\n",
        "    for i in range(len(V)):\n",
        "        for j in range(len(V)):\n",
        "            M[i,j] = find_M(V[i], V[j], sp)   \n",
        "    return M"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHazUHufMMWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "M = compute_PMI(sp, V)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_6pZApxOM6m",
        "colab_type": "code",
        "outputId": "d5414a6f-314a-4dd2-e0a0-3de34abb5a20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "M[:5, :5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4.76824443,  2.14964053,  0.70095035,  1.9183114 , -2.39743607],\n",
              "       [ 2.14964053,  2.22227972,  1.80320896,  3.37724494, -0.53303742],\n",
              "       [ 0.70095035,  1.80320896,  0.32553124,  1.41772914, -0.56264341],\n",
              "       [ 1.9183114 ,  3.37724494,  1.41772914,  3.1459158 , -0.47668448],\n",
              "       [-2.39743607, -0.53303742, -0.56264341, -0.47668448, -1.34244441]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekVWXKvfOJdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Part (b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB6r4BuNOZly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# factorize the matrix M to obtain word embeddings. Take the k-SVD of M with \n",
        "# k = 50 using scipy package"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FS61SVVlzwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(U,s,V) = scipy.sparse.linalg.svds(scipy.sparse.csr_matrix(M), k = 50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag5DwqXwPXGg",
        "colab_type": "code",
        "outputId": "3387d9a6-79b9-48b7-a09f-310d0c13c408",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "U[:5, :5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.02253238,  0.0134218 ,  0.01871072, -0.00329062, -0.01858585],\n",
              "       [ 0.00349842, -0.00388213, -0.00597445,  0.00532572,  0.00590599],\n",
              "       [-0.08447695,  0.03435381,  0.03832418, -0.02966298, -0.06234913],\n",
              "       [ 0.00484249, -0.00667755,  0.00764245, -0.00129963, -0.00294504],\n",
              "       [-0.00414873, -0.06328248,  0.07092509,  0.08421068, -0.0638046 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf8x-5I8PaM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = np.diag(s)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDOWIn4cPZ_6",
        "colab_type": "code",
        "outputId": "5afd1c0e-f96c-4aaa-ffb6-b4d377d2e7f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "V[:5, :5] "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.02253238,  0.00349842, -0.08447695,  0.00484249, -0.00414873],\n",
              "       [ 0.0134218 , -0.00388213,  0.03435381, -0.00667755, -0.06328248],\n",
              "       [ 0.01871072, -0.00597445,  0.03832418,  0.00764245,  0.07092509],\n",
              "       [-0.00329062,  0.00532572, -0.02966298, -0.00129963,  0.08421068],\n",
              "       [-0.01858585,  0.00590599, -0.06234913, -0.00294504, -0.0638046 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xs73np3QN56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Part (c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLW4ZvjUlzy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W = np.matmul(U,np.sqrt(s))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tG82WYzd7fe",
        "colab_type": "code",
        "outputId": "c05408bd-c674-4c5c-9840-7c2e5d1bcdf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "W[:5, :5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.16691093,  0.09983719,  0.13945241, -0.02457296, -0.13973563],\n",
              "       [ 0.02591488, -0.02887699, -0.04452798,  0.03977023,  0.04440354],\n",
              "       [-0.62577173,  0.25553859,  0.28563296, -0.22151052, -0.46876499],\n",
              "       [ 0.03587122, -0.04967053,  0.05695978, -0.00970509, -0.02214195],\n",
              "       [-0.03073214, -0.4707226 ,  0.52860995,  0.62884958, -0.47970772]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v13lbs0CQZKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# serialize PMI Word embeddings to disk "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQuw5qwvQYD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(W, gzip.open(\"pmi_learned.pkl.gz\",\"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNl63iQfQiuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Part (d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ri2dkOLegPiX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First, we need to decide how we will define \"closeness\". \n",
        "# We could try both cosine angular distance and euclidian distance and see\n",
        "# choose the one that works better "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H94b_IMeQnyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a function that computes \"closeness\": cosine of the angle between two \n",
        "# normalized word vectors "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJU5xXq7lz1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_cosine(a, b):\n",
        "    return (np.dot(a,b)/(np.linalg.norm(a)*np.linalg.norm(b)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uxn02EJogcex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a function that computes \"closeness\": euclidian distance between word \n",
        "# vectors "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug8sJeqEdUvc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_sim(a, b):\n",
        "    return scipy.spatial.distance.euclidean(a, b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkHOPWsSRIhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function that finds the 5 closest words in the embedding space "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0PwwaSFQsPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_closest(W, V, w):\n",
        "    dic = {}\n",
        "    w_index = V.index(w)\n",
        "    w_embed = W[w_index]\n",
        "    for i in range(len(V)):\n",
        "        if i != w_index:\n",
        "            dic[i] = compute_cosine(w_embed, W[i])\n",
        "    top_five = [top[0] for top in collections.Counter(dic).most_common(5)]\n",
        "    return [V[ind] for ind in top_five]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_ljdwBYlz3n",
        "colab_type": "code",
        "outputId": "e369ac64-79fb-4333-daeb-28a196aed461",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Let's first find 5 closest words for \"physics\"\n",
        "print(find_closest(W, V, \"physics\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['mathematics', 'chemistry', 'mathematical', 'einstein', 'geometry']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQCHx0z7j0ld",
        "colab_type": "code",
        "outputId": "195f7fa8-4fa8-4e9b-efe1-b7900374fe31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(find_closest(W, V, \"republican\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['candidate', 'presidential', 'bush', 'vice', 'democratic']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQGv23h2j0nZ",
        "colab_type": "code",
        "outputId": "1c05b3e2-c9e0-4c72-fff5-3c929e7dc7c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(find_closest(W, V, \"einstein\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['physics', 'mathematics', 'albert', 'scientific', 'turing']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Pde5KSrj0pf",
        "colab_type": "code",
        "outputId": "c9e4ff3d-b459-4dd1-836a-4f24411bacbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(find_closest(W, V, \"algebra\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['algebraic', 'theorem', 'mathematical', 'geometry', 'element']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aj9ktLuj0rk",
        "colab_type": "code",
        "outputId": "1db9410e-4bf0-4e7e-9e4e-2e11f10f4832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(find_closest(W, V, \"fish\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['farming', 'rich', 'iron', 'wild', 'trees']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B7ZomKamJ5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The results show that even by common sense, the 5 closest context words \n",
        "# for the given words are mutually related. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcXPNQuvjzXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Part (e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jB-ZrFK2n-x1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a function that computes operations on linear substructure "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_MvxvMDmJ8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_sub(W, V, expression):  \n",
        "    dic = {}\n",
        "    substruc = 0\n",
        "    for i in range(len(expression)):\n",
        "        if i == 0:\n",
        "            substruc -= W[V.index(expression[i])]\n",
        "        else: \n",
        "            substruc += W[V.index(expression[i])]\n",
        "\n",
        "    for k in range(len(V)):\n",
        "        dic[k] = compute_cosine(substruc, W[k])\n",
        "    top_five = [top[0] for top in collections.Counter(dic).most_common(5)]\n",
        "\n",
        "    return [V[ind] for ind in top_five]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WfZefkjreEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Try analogy given in the exercise "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbcxrBGomJ-b",
        "colab_type": "code",
        "outputId": "62e23eee-75ba-4d53-c4f0-23de552dfebc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(compute_sub(W, V, [\"france\", \"paris\", \"england\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['england', 'london', 'bishop', 'canterbury', 'rome']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA-hReDQvS_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Interestingly, we get \"London\" as one of the results. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Arsfk5iardyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Try 3 different analogies "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MesnnOKTr5tq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try republican: democrat = conservative: ?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVfLvja7mKAx",
        "colab_type": "code",
        "outputId": "778470e0-0b40-4052-f81e-a52379b398f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(compute_sub(W, V, [\"republican\", \"democrat\", \"conservative\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['anglicans', 'counted', 'theologians', 'abbots', 'merchants']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrqyNvR7vZe_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Although we didn't get \"liberal\", we did get groups that often represent the\n",
        "# liberal facade in religion, academia, and economy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLV7vGSGsBlX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try president: politics = pope ?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVSFRY7lmKDX",
        "colab_type": "code",
        "outputId": "e461c038-2fb6-4134-fec3-1c3df0a0e509",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(compute_sub(W, V, [\"president\", \"politics\", \"pope\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['byzantine', 'vi', 'vii', 'afonso', 'christianity']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11tsuGGhwEU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We get \"christianity\" which I believe is an amazing catch. Perhaps even better\n",
        "# than the expected \"religion\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcpUVIDAwNYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try  war: peace = fight: ?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zmk_bOWPmKFe",
        "colab_type": "code",
        "outputId": "f19af404-0263-46e8-c3c7-14bcae24fcaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(compute_sub(W, V, [\"war\", \"peace\", \"fight\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['reformed', 'apostolic', 'canonical', 'maintains', 'affiliated']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nnj2Sqm5xB3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We are testing very abstract relations here, but it seems that the algorithm \n",
        "# is captureing the differences in the abstract notions. The resulting words are \n",
        "# distantly related to peace, but they are clear opposites of fight. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3fI29xsmKKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLFfz6rHmKMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv7KJBs-mKOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}